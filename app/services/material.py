import os
import random
from typing import List
from urllib.parse import urlencode

import requests
from loguru import logger
from moviepy.video.io.VideoFileClip import VideoFileClip

from app.config import config
from app.models.schema import MaterialInfo, VideoAspect, VideoConcatMode
from app.utils import utils

requested_count = 0


def get_api_key(cfg_key: str):
    api_keys = config.app.get(cfg_key)
    if not api_keys:
        raise ValueError(
            f"\n\n##### {cfg_key} is not set #####\n\nPlease set it in the config.toml file: {config.config_file}\n\n"
            f"{utils.to_json(config.app)}"
        )

    # if only one key is provided, return it
    if isinstance(api_keys, str):
        return api_keys

    global requested_count
    requested_count += 1
    return api_keys[requested_count % len(api_keys)]


def search_videos_pexels(
    search_term: str,
    minimum_duration: int,
    video_aspect: VideoAspect = VideoAspect.portrait,
    max_results: int = 20,  # æ–°å¢ï¼šæœ€å¤§ç»“æœæ•°
) -> List[MaterialInfo]:
    """
    ä½¿ç”¨Pexels APIæœç´¢è§†é¢‘ç´ æ
    
    ä¼˜åŒ–ç‚¹ï¼š
    1. æ”¯æŒå¤šè¯­è¨€æœç´¢ï¼ˆä¸­è‹±æ–‡å…³é”®è¯ï¼‰
    2. æ™ºèƒ½è´¨é‡ç­›é€‰ï¼ˆä¼˜å…ˆé€‰æ‹©é«˜è´¨é‡è§†é¢‘ï¼‰
    3. æ”¯æŒç›¸å…³åº¦æ’åºï¼ˆPexels APIè‡ªåŠ¨æŒ‰ç›¸å…³åº¦æ’åºï¼‰
    4. æ”¯æŒç²¾ç¡®åˆ†è¾¨ç‡åŒ¹é…å’Œé™çº§åŒ¹é…
    """
    aspect = VideoAspect(video_aspect)
    video_orientation = aspect.name
    video_width, video_height = aspect.to_resolution()
    api_key = get_api_key("pexels_api_keys")
    headers = {
        "Authorization": api_key,
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36",
    }
    
    # ä¼˜åŒ–æœç´¢å‚æ•°ï¼šå¢åŠ ç»“æœæ•°é‡ï¼Œæé«˜å‘½ä¸­ç‡
    params = {
        "query": search_term, 
        "per_page": min(max_results, 80),  # Pexelsæœ€å¤šæ”¯æŒ80ä¸ª/é¡µ
        "orientation": video_orientation,
        "size": "large",  # ä¼˜å…ˆé«˜è´¨é‡è§†é¢‘
    }
    query_url = f"https://api.pexels.com/videos/search?{urlencode(params)}"
    logger.info(f"searching videos: {query_url}, with proxies: {config.proxy}")

    try:
        r = requests.get(
            query_url,
            headers=headers,
            proxies=config.proxy,
            verify=False,
            timeout=(30, 60),
        )
        response = r.json()
        video_items = []
        if "videos" not in response:
            logger.error(f"search videos failed: {response}")
            return video_items
        
        videos = response["videos"]
        logger.info(f"pexels returned {len(videos)} videos for '{search_term}'")
        
        # æŒ‰ç›¸å…³åº¦å’Œè´¨é‡ç­›é€‰è§†é¢‘
        for v in videos:
            duration = v["duration"]
            # æ£€æŸ¥è§†é¢‘æ˜¯å¦æ»¡è¶³æœ€å°æ—¶é•¿è¦æ±‚
            if duration < minimum_duration:
                continue
            
            video_files = v["video_files"]
            # æŒ‰è´¨é‡ä¼˜å…ˆçº§æ’åºï¼šç²¾ç¡®åŒ¹é… > é«˜è´¨é‡é™çº§ > æ™®é€šé™çº§
            matched_video = None
            best_fallback = None
            
            for video in video_files:
                w = int(video["width"])
                h = int(video["height"])
                quality = video.get("quality", "")
                
                # ç­–ç•¥1ï¼šç²¾ç¡®åˆ†è¾¨ç‡åŒ¹é…ï¼ˆæœ€ä¼˜ï¼‰
                if w == video_width and h == video_height:
                    matched_video = video
                    break
                
                # ç­–ç•¥2ï¼šå®½é«˜æ¯”åŒ¹é… + HDè´¨é‡ï¼ˆæ¬¡ä¼˜ï¼‰
                if not best_fallback and quality == "hd":
                    aspect_ratio_target = video_width / video_height
                    aspect_ratio_current = w / h if h > 0 else 0
                    # å®½é«˜æ¯”è¯¯å·®åœ¨10%ä»¥å†…
                    if abs(aspect_ratio_current - aspect_ratio_target) / aspect_ratio_target < 0.1:
                        if w >= video_width * 0.8:  # å®½åº¦è‡³å°‘æ˜¯ç›®æ ‡çš„80%
                            best_fallback = video
            
            # ä½¿ç”¨åŒ¹é…çš„è§†é¢‘
            selected_video = matched_video or best_fallback
            if selected_video:
                item = MaterialInfo()
                item.provider = "pexels"
                item.url = selected_video["link"]
                item.duration = duration
                video_items.append(item)
                logger.debug(f"selected video: {selected_video['width']}x{selected_video['height']} ({selected_video.get('quality', 'unknown')})")
        
        logger.info(f"filtered {len(video_items)} suitable videos from pexels")
        return video_items
        
    except Exception as e:
        logger.error(f"search videos failed: {str(e)}")

    return []


def search_videos_pixabay(
    search_term: str,
    minimum_duration: int,
    video_aspect: VideoAspect = VideoAspect.portrait,
    max_results: int = 50,  # æ–°å¢ï¼šæœ€å¤§ç»“æœæ•°
) -> List[MaterialInfo]:
    aspect = VideoAspect(video_aspect)

    video_width, video_height = aspect.to_resolution()

    api_key = get_api_key("pixabay_api_keys")
    # Build URL
    params = {
        "q": search_term,
        "video_type": "all",  # Accepted values: "all", "film", "animation"
        "per_page": min(max_results, 200),  # Pixabayæœ€å¤š200ä¸ª/é¡µ
        "key": api_key,
    }
    query_url = f"https://pixabay.com/api/videos/?{urlencode(params)}"
    logger.info(f"searching videos: {query_url}, with proxies: {config.proxy}")

    try:
        r = requests.get(
            query_url, proxies=config.proxy, verify=False, timeout=(30, 60)
        )
        response = r.json()
        video_items = []
        if "hits" not in response:
            logger.error(f"search videos failed: {response}")
            return video_items
        videos = response["hits"]
        # loop through each video in the result
        for v in videos:
            duration = v["duration"]
            # check if video has desired minimum duration
            if duration < minimum_duration:
                continue
            video_files = v["videos"]
            # loop through each url to determine the best quality
            for video_type in video_files:
                video = video_files[video_type]
                w = int(video["width"])
                # h = int(video["height"])
                if w >= video_width:
                    item = MaterialInfo()
                    item.provider = "pixabay"
                    item.url = video["url"]
                    item.duration = duration
                    video_items.append(item)
                    break
        return video_items
    except Exception as e:
        logger.error(f"search videos failed: {str(e)}")

    return []


def save_video(video_url: str, save_dir: str = "") -> str:
    if not save_dir:
        save_dir = utils.storage_dir("cache_videos")

    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    url_without_query = video_url.split("?")[0]
    url_hash = utils.md5(url_without_query)
    video_id = f"vid-{url_hash}"
    video_path = f"{save_dir}/{video_id}.mp4"

    # if video already exists, return the path
    if os.path.exists(video_path) and os.path.getsize(video_path) > 0:
        logger.info(f"video already exists: {video_path}")
        return video_path

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36"
    }

    # if video does not exist, download it
    with open(video_path, "wb") as f:
        f.write(
            requests.get(
                video_url,
                headers=headers,
                proxies=config.proxy,
                verify=False,
                timeout=(60, 240),
            ).content
        )

    if os.path.exists(video_path) and os.path.getsize(video_path) > 0:
        try:
            clip = VideoFileClip(video_path)
            duration = clip.duration
            fps = clip.fps
            clip.close()
            if duration > 0 and fps > 0:
                return video_path
        except Exception as e:
            try:
                os.remove(video_path)
            except Exception:
                pass
            logger.warning(f"invalid video file: {video_path} => {str(e)}")
    return ""


def download_videos(
    task_id: str,
    search_terms: List[str],
    source: str = "pexels",
    video_aspect: VideoAspect = VideoAspect.portrait,
    video_contact_mode: VideoConcatMode = VideoConcatMode.random,
    audio_duration: float = 0.0,
    max_clip_duration: int = 5,
) -> List[str]:
    """
    ä¸‹è½½è§†é¢‘ç´ æ
    
    ä¼˜åŒ–ç‚¹ï¼š
    1. æ™ºèƒ½å»é‡ï¼šé¿å…é‡å¤è§†é¢‘
    2. åŠ¨æ€è°ƒæ•´æœç´¢ç­–ç•¥ï¼šå¦‚æœå…³é”®è¯æœä¸åˆ°è¶³å¤Ÿç´ æï¼Œè‡ªåŠ¨æ‰©å¤§æœç´¢èŒƒå›´
    3. è´¨é‡ä¼˜å…ˆï¼šä¼˜å…ˆä¸‹è½½é«˜ç›¸å…³åº¦å’Œé«˜è´¨é‡çš„è§†é¢‘
    4. è¿›åº¦è·Ÿè¸ªï¼šè¯¦ç»†è®°å½•æœç´¢å’Œä¸‹è½½è¿›åº¦
    """
    valid_video_items = []
    valid_video_urls = set()  # ä½¿ç”¨setåŠ é€ŸurlæŸ¥æ‰¾
    found_duration = 0.0
    search_videos = search_videos_pexels
    if source == "pixabay":
        search_videos = search_videos_pixabay

    # ç¬¬ä¸€è½®ï¼šæŒ‰åŸå§‹å…³é”®è¯æœç´¢
    logger.info(f"ğŸ” å¼€å§‹æœç´¢è§†é¢‘ç´ æï¼Œå…³é”®è¯: {search_terms}")
    
    for search_term in search_terms:
        if not search_term or not search_term.strip():
            continue
            
        logger.info(f"  - æœç´¢å…³é”®è¯: '{search_term}'")
        video_items = search_videos(
            search_term=search_term.strip(),
            minimum_duration=max_clip_duration,
            video_aspect=video_aspect,
            max_results=40,  # å¢åŠ æœç´¢ç»“æœæ•°
        )
        
        # å»é‡å¹¶æ·»åŠ åˆ°å€™é€‰åˆ—è¡¨
        new_count = 0
        for item in video_items:
            if item.url not in valid_video_urls:
                valid_video_items.append(item)
                valid_video_urls.add(item.url)
                found_duration += item.duration
                new_count += 1
        
        logger.info(f"    âœ… æ‰¾åˆ° {len(video_items)} ä¸ªè§†é¢‘ï¼Œæ–°å¢ {new_count} ä¸ªï¼ˆå»é‡åï¼‰")

    # ç¬¬äºŒè½®ï¼šå¦‚æœç´ æä¸è¶³ï¼Œå°è¯•ç»„åˆå…³é”®è¯æœç´¢
    if found_duration < audio_duration * 0.8 and len(search_terms) > 1:
        logger.warning(f"  âš ï¸  ç´ æä¸è¶³ï¼ˆå·²æ‰¾åˆ° {found_duration:.1f}sï¼Œéœ€è¦ {audio_duration:.1f}sï¼‰")
        logger.info(f"  ğŸ” å°è¯•ç»„åˆå…³é”®è¯æœç´¢...")
        
        # å–å‰2-3ä¸ªæ ¸å¿ƒå…³é”®è¯ç»„åˆ
        combined_term = " ".join(search_terms[:min(3, len(search_terms))])
        video_items = search_videos(
            search_term=combined_term,
            minimum_duration=max_clip_duration,
            video_aspect=video_aspect,
            max_results=30,
        )
        
        new_count = 0
        for item in video_items:
            if item.url not in valid_video_urls:
                valid_video_items.append(item)
                valid_video_urls.add(item.url)
                found_duration += item.duration
                new_count += 1
        
        if new_count > 0:
            logger.info(f"    âœ… ç»„åˆæœç´¢æ–°å¢ {new_count} ä¸ªè§†é¢‘")

    logger.info(
        f"""
â”Œâ”€â”€ æœç´¢ç»“æœç»Ÿè®¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ‰¾åˆ°è§†é¢‘æ€»æ•°: {len(valid_video_items)} ä¸ª                             â”‚
â”‚ éœ€è¦æ—¶é•¿: {audio_duration:.1f} ç§’                               â”‚
â”‚ æ‰¾åˆ°æ—¶é•¿: {found_duration:.1f} ç§’                               â”‚
â”‚ è¦†ç›–ç‡: {min(100, found_duration/audio_duration*100 if audio_duration > 0 else 0):.1f}%                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
    )
    
    video_paths = []
    material_directory = config.app.get("material_directory", "").strip()
    if material_directory == "task":
        material_directory = utils.task_dir(task_id)
    elif material_directory and not os.path.isdir(material_directory):
        material_directory = ""

    # æŒ‰æ¨¡å¼æ’åºï¼šéšæœºæˆ–é¡ºåº
    if video_contact_mode.value == VideoConcatMode.random.value:
        random.shuffle(valid_video_items)
        logger.info("ğŸ² ä½¿ç”¨éšæœºé¡ºåºä¸‹è½½")
    else:
        logger.info("ğŸ“Š æŒ‰ç›¸å…³åº¦é¡ºåºä¸‹è½½")

    # ä¸‹è½½è§†é¢‘
    logger.info("\nğŸ“¥ å¼€å§‹ä¸‹è½½è§†é¢‘ç´ æ...")
    total_duration = 0.0
    downloaded_count = 0
    
    for idx, item in enumerate(valid_video_items, 1):
        try:
            logger.info(f"  [{idx}/{len(valid_video_items)}] ä¸‹è½½: {item.url[:80]}...")
            saved_video_path = save_video(
                video_url=item.url, save_dir=material_directory
            )
            if saved_video_path:
                logger.success(f"    âœ… ä¿å­˜: {os.path.basename(saved_video_path)}")
                video_paths.append(saved_video_path)
                downloaded_count += 1
                seconds = min(max_clip_duration, item.duration)
                total_duration += seconds
                
                # åˆ¤æ–­æ˜¯å¦å·²ç»è¶³å¤Ÿ
                if total_duration >= audio_duration:
                    logger.success(
                        f"    âœ¨ å·²è¾¾åˆ°ç›®æ ‡æ—¶é•¿ ({total_duration:.1f}s >= {audio_duration:.1f}s)ï¼Œåœæ­¢ä¸‹è½½"
                    )
                    break
        except Exception as e:
            logger.error(f"    âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
    
    logger.success(
        f"""
â”Œâ”€â”€ ä¸‹è½½å®Œæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æˆåŠŸä¸‹è½½: {downloaded_count} ä¸ªè§†é¢‘                              â”‚
â”‚ æ€»æ—¶é•¿: {total_duration:.1f} ç§’                                  â”‚
â”‚ ç›®æ ‡æ—¶é•¿: {audio_duration:.1f} ç§’                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """
    )
    return video_paths


if __name__ == "__main__":
    download_videos(
        "test123", ["Money Exchange Medium"], audio_duration=100, source="pixabay"
    )
